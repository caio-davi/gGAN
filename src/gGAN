#!/usr/bin/env python

import os
import sys
from sys import exit
import argparse
import shutil
import model

path = '/gGAN/src/'

def check_afd(afd):
    enabled_models = ['0.07', '0.10', '0.21', 'SVM']
    if afd in enabled_models:
        print("[INFO] Running GAN with a max allelic frequency proximity of:", afd)
    else:
        print("[ERROR] Invalid model set:", afd)
        exit()
    return afd.replace(".", "")

def load_datasets(path, afd, dim, syn):
    import load_data
    import pre_processing
    if(syn):
        if(not pre_processing.check_current_sampling(afd)):
            print("[ERROR] Current synthetic data doesn't match [afd] option.", dim)
            exit()
        print('-------------ENTRA AQUI -------------------------------------')
        print("[INFO] Loading synthetic labeled data...")    
        labeled_dataset = load_data.load_labeled_samples(path + 'data/synthetic/labeled')
    else:
        print("[INFO] Pre-Processing Data...")
        print("[INFO] Dimensions: ", dim)
        pre_processing.init(path, afd, dim)

        print("[INFO] Loading original labeled data...")
        labeled_dataset = load_data.load_labeled_samples(path + 'data/labeled')
    
    print("[INFO] Loading original unlabeled data...")
    unlabeled_dataset = load_data.load_unlabeled_samples(path + 'data/unlabeled')
    # generate train and test LABELED datasets
    labeled_train_dataset, labeled_test_dataset = load_data.generate_supervised_datasets(labeled_dataset)
    # generate train and test UNLABELED datasets
    unlabeled_train_dataset, unlabeled_test_dataset = load_data.generate_unsupervised_datasets(unlabeled_dataset)
    datasets = {
        'labeled_train_dataset' : labeled_train_dataset,
        'labeled_test_dataset' : labeled_test_dataset,
        'unlabeled_train_dataset' : unlabeled_train_dataset,
        'unlabeled_test_dataset' : unlabeled_test_dataset
    }
    return datasets

def main():
    # parse args
    parser = argparse.ArgumentParser()
    parser.add_argument("cmd", help="Action to perform. Opitons: run : run, clear, test.")
    parser.add_argument("--afd", help="The threshold for the Allelic Freqeuncy Distance. Options are: 0.07, 0.10, 0.21, SVM")
#    parser.add_argument("--dim", help="Number of dimensions of the formated sample. Options are: 1 (Conv1D) or 2 (Conv2D)")
    parser.add_argument("--syn", type=bool, help="Run training+test with synthetic data.")
    args = parser.parse_args()

    args.dim = '1'

    enabled_dims = [1,2]

    if not (float(args.dim) in enabled_dims):
        print("[ERROR] Invalid Dimension option:", args.dim)
        exit()

    if args.cmd == 'clear':
        print("[INFO] Deleting all previus results...")
        shutil.rmtree(path + "run/")
        exit()

    elif args.cmd == 'test':

        afd = check_afd(args.afd)

        from keras.models import load_model


        c_model = load_model('/gGAN/backups/'+afd+'/c_model.h5')
        d_model = load_model('/gGAN/backups/'+afd+'/d_model.h5', compile=True)
        g_model = load_model('/gGAN/backups/'+afd+'/g_model.h5', compile=True)

        datasets = load_datasets(path, afd, args.dim, args.syn)

        model.tests(g_model, d_model, c_model, 100, datasets['labeled_test_dataset'], datasets['unlabeled_test_dataset'])


    elif args.cmd == 'run':

        afd = check_afd(args.afd)
        
        sys.path.insert(1, path +'models/')

        if(str(afd) == 'SVM'):
            net_model = __import__('model_'+args.dim+'_007', globals(), locals(), 0)
        else:
            net_model = __import__('model_'+args.dim+'_'+afd, globals(), locals(), 0)

        datasets = load_datasets(path, afd, args.dim, args.syn)

        # train
        print("[INFO] Training model...")
        model.train_instances(datasets, net_model, path)
        print("[DONE] Finished.")
    
    else:
        print("[ERROR] Invalid action.")


if __name__ == '__main__':
    main()